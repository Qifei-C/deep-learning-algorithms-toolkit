# Adversarial Robustness

This project investigates the adversarial robustness of Convolutional Neural Networks (CNNs), featuring an implementation of the Fast Gradient Sign Method (FGSM) attack.

## üöÄ Core Components

*   **All-CNN Model**: An implementation of the "All Convolutional Net" architecture for image classification.
*   **Adversarial Attacker**: A component that implements the FGSM attack to generate adversarial examples.
*   **Data Augmentation**: Scripts for applying data augmentation techniques to improve model robustness.
*   **Training and Evaluation**: A trainer to train the CNN model and evaluate its performance against both clean and adversarial data.

## üõ†Ô∏è Usage

To run the project, you can execute the main script, which will train the CNN model on the CIFAR-10 dataset, perform an FGSM attack, and evaluate the model's robustness.
